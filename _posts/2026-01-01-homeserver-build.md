---
title: "홈서버 구축기: 추천시스템부터 이커머스까지 돌리기 위한 데스크탑 서버"
date: 2026-01-01 00:00:00 +0900
author: oogie
categories: [infra]
tags: [homeserver,hardware]     # TAG names should always be lowercase]
use_math: false
img_base: /assets/img/2026-01-01-homeserver-build
---

## TL;DR

추천시스템, 검색, MLOps, 이커머스를 직접 설계하고 운영해보기 위해 홈서버를 맞췄다. Colab이나 RunPod 같은 클라우드 GPU는 컨테이너 기반의 연구용 환경이라 실제 서비스 아키텍처를 경험하기에 부적합하다고 판단했다. Ryzen 9900X, DDR5 64GB, RTX 5060 Ti 16GB x2, ASUS ROG STRIX B650E-E 조합으로 구성했다.

---

## 1. 왜 홈서버인가?

### 하고 싶은 것들

개인적으로 추천시스템, 검색, MLOps에 관심이 많고, 궁극적으로는 이커머스를 직접 개발해보고 싶다는 목표가 있다. 이를 위해서는 다음이 전부 한 환경에서 돌아가야 한다:

- **백엔드** (FastAPI 등)
- **프론트엔드** (React 등)
- **데이터베이스** (PostgreSQL, Redis 등)
- **ML 학습 및 추론** (PyTorch, 추천 모델 등)
- **MLOps 파이프라인** (Airflow, Docker, 모니터링 등)

단순히 모델 하나 학습시키는 게 아니라, **학습 → 추론 → 배치/실시간 서빙**까지의 아키텍처 전체를 직접 설계하고 경험해보고 싶었다.

### 클라우드 GPU의 한계

GPU가 필요하다는 건 명확했다. 그런데 Colab이나 RunPod 같은 서비스를 쓰면 되지 않나?

사실 연구 목적이라면 충분하다. 하지만 내가 하고 싶은 건 **서비스 아키텍처를 직접 구축하는 것**이었다.

클라우드 GPU 서비스들의 공통적인 한계:

- **컨테이너 기반 환경**: 세션이 끊기면 환경이 날아가고, 영속적인 서비스 운영이 어렵다
- **연구용 설계**: 모델 학습이나 노트북 실행에 최적화되어 있지, DB + 백엔드 + 프론트 + ML이 동시에 돌아가는 구조가 아니다
- **아키텍처 경험 불가**: 실제로 서버에 여러 서비스를 띄우고 네트워크를 구성하고 리소스를 관리하는 경험을 할 수 없다

결국 **내 서버가 필요했다.** 데스크탑을 한 대 맞추고 서버용으로 돌리기로 했다.

---

## 2. 스펙 선정 기준

예산에는 한계가 있으니, 각 부품마다 **왜 이 스펙이 필요한지**를 명확히 하고 선택했다.

핵심 요구사항:

- GPU 2장을 꽂아서 DDP(Distributed Data Parallel) 학습까지 해보고 싶다
- DB, 백엔드, 프론트, ML 워크로드가 동시에 돌아가야 한다
- 메모리는 최대한 넉넉하게
- 예산 안에서 최선의 선택

---

## 3. 부품별 선택 이유

### CPU: AMD Ryzen 9 9900X

DB, 백엔드, 프론트엔드, MLOps 파이프라인이 동시에 돌아가야 하는 환경이다 보니 **코어 수**가 중요했다. PostgreSQL, FastAPI 워커, Docker 컨테이너들, Airflow 스케줄러 등이 동시에 CPU를 점유하게 된다.

9900X는 12코어 24스레드로, 예산 범위 내에서 코어 수가 높은 편에 속하는 선택이었다.

### 메모리: DDR5 5600 64GB (32GB x 2)

메모리는 가용 예산에서 최대한 넉넉하게 잡았다. 이유는 단순하다:

- PyTorch 모델 학습 시 데이터 로딩만으로도 수 GB를 잡아먹고
- PostgreSQL, Redis 같은 DB도 메모리를 상당히 사용하며
- Docker 컨테이너를 여러 개 띄우면 각각이 메모리를 점유한다

64GB면 위 워크로드를 동시에 돌리기에 충분한 수준이라고 판단했다.


### GPU: RTX 5060 Ti 16GB x 2

GPU 선택에서 가장 중요하게 본 건 **VRAM**이다. 추천 모델이든 임베딩 모델이든, VRAM이 부족하면 배치 사이즈를 줄여야 하고 학습 효율이 크게 떨어진다.

5060 Ti 16GB를 2장 선택한 이유:

- **VRAM 16GB**: 예산 대비 VRAM이 가장 넉넉한 선택지
- **2장 구성**: PyTorch DDP(Distributed Data Parallel)를 직접 경험해보고 싶었다. 단일 GPU 학습과 분산 학습은 코드 구조부터 다르고, 실무에서도 많이 쓰이는 패턴이라 직접 해보는 게 중요하다고 판단했다

### 메인보드: ASUS ROG STRIX B650E-E

메인보드 선택이 사실 가장 까다로웠다. GPU 2장을 꽂으려면 **PCIe 레인 구성**이 핵심이다.

이상적으로는 x8/x8 구성이 좋지만, 이를 지원하는 보드는 거의 X670E 이상의 고가 보드들이고 가격이 70만 원을 넘어간다.

ASUS ROG STRIX B650E-E를 선택한 이유:

- **PCIe 5.0을 두 GPU 슬롯 모두에 지원**하는 거의 유일한 B 보드
- x8/x4로 감속되긴 하지만, 학습/추론 워크로드에서 PCIe 대역폭이 병목이 되는 경우는 드물다
- **30만 원대**로, x8/x8 보드 대비 절반 이하의 가격

가성비와 듀얼 GPU 지원을 동시에 만족하는 사실상 유일한 선택이었다.

![ASUS ROG STRIX B650E-E]({{ page.img_base }}/motherboard.png){: width="500" }

### SSD: Samsung 990 Pro 2TB

데이터셋 저장, Docker 이미지, DB 데이터 등을 고려하면 1TB는 금방 차기 때문에 2TB로 잡았다. 990 Pro는 읽기/쓰기 속도가 충분히 빠르고 안정성도 검증된 제품이다.

### PSU: 1200W

GPU 2장에 고성능 CPU를 돌리려면 전력 소모가 상당하다. 여유 있게 1200W로 잡았다. PSU는 아끼면 안 되는 부품이라, 넉넉한 용량으로 안정적인 운영을 우선했다.

---

## 4. 최종 스펙 정리

| 부품 | 제품 | 선택 이유 |
|------|------|----------|
| CPU | AMD Ryzen 9 9900X (12C/24T) | 멀티 워크로드용 높은 코어 수 |
| RAM | DDR5 5600 64GB (32GB x 2) | 예산 내 최대 용량 |
| GPU | RTX 5060 Ti 16GB x 2 | VRAM 중시 + DDP 경험 |
| 메인보드 | ASUS ROG STRIX B650E-E | PCIe 5.0 듀얼 GPU, 30만원대 B보드 유일 |
| SSD | Samsung 990 Pro 2TB | 데이터셋 + Docker + DB 저장 |
| PSU | 1200W | GPU 2장 + 고성능 CPU 안정 운영 |

![부품 구성]({{ page.img_base }}/components.jpeg){: width="500" }

---

## 5. 마무리

이 서버 위에서 Ubuntu를 깔고, Docker 기반으로 서비스들을 하나씩 올려나갈 예정이다. 백엔드, DB, ML 파이프라인, 프론트엔드까지 전부 이 한 대에서 돌리는 게 목표다.

클라우드 서비스를 쓰면 편하긴 하지만, 직접 서버를 구축하고 운영하면서 얻는 경험은 분명 다를 거라고 생각한다. 네트워크 설정, 리소스 관리, 서비스 간 통신 구성 같은 것들은 직접 해봐야 체감이 되는 영역이니까.

다음 글에서는 이 서버에 Ubuntu를 설치하고 외부에서 SSH로 접속하는 과정을 정리할 예정이다.
